{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение в обработку естественного языка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Урок 1. Предобработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществим предобработку данных с Твиттера, чтобы отчищенный данные в дальнейшем использовать для задачи классификации. Данный датасет содержит негативные (label = 1) и нейтральные (label = 0) высказывания.\n",
    "Для работы объединим train_df и test_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apostrophe_dict = {\n",
    "\"ain't\": \"am not / are not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is\",\n",
    "\"i'd\": \"I had / I would\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I shall / I will\",\n",
    "\"i'll've\": \"I shall have / I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "short_word_dict = {\n",
    "\"121\": \"one to one\",\n",
    "\"a/s/l\": \"age, sex, location\",\n",
    "\"adn\": \"any day now\",\n",
    "\"afaik\": \"as far as I know\",\n",
    "\"afk\": \"away from keyboard\",\n",
    "\"aight\": \"alright\",\n",
    "\"alol\": \"actually laughing out loud\",\n",
    "\"b4\": \"before\",\n",
    "\"b4n\": \"bye for now\",\n",
    "\"bak\": \"back at the keyboard\",\n",
    "\"bf\": \"boyfriend\",\n",
    "\"bff\": \"best friends forever\",\n",
    "\"bfn\": \"bye for now\",\n",
    "\"bg\": \"big grin\",\n",
    "\"bta\": \"but then again\",\n",
    "\"btw\": \"by the way\",\n",
    "\"cid\": \"crying in disgrace\",\n",
    "\"cnp\": \"continued in my next post\",\n",
    "\"cp\": \"chat post\",\n",
    "\"cu\": \"see you\",\n",
    "\"cul\": \"see you later\",\n",
    "\"cul8r\": \"see you later\",\n",
    "\"cya\": \"bye\",\n",
    "\"cyo\": \"see you online\",\n",
    "\"dbau\": \"doing business as usual\",\n",
    "\"fud\": \"fear, uncertainty, and doubt\",\n",
    "\"fwiw\": \"for what it's worth\",\n",
    "\"fyi\": \"for your information\",\n",
    "\"g\": \"grin\",\n",
    "\"g2g\": \"got to go\",\n",
    "\"ga\": \"go ahead\",\n",
    "\"gal\": \"get a life\",\n",
    "\"gf\": \"girlfriend\",\n",
    "\"gfn\": \"gone for now\",\n",
    "\"gmbo\": \"giggling my butt off\",\n",
    "\"gmta\": \"great minds think alike\",\n",
    "\"h8\": \"hate\",\n",
    "\"hagn\": \"have a good night\",\n",
    "\"hdop\": \"help delete online predators\",\n",
    "\"hhis\": \"hanging head in shame\",\n",
    "\"iac\": \"in any case\",\n",
    "\"ianal\": \"I am not a lawyer\",\n",
    "\"ic\": \"I see\",\n",
    "\"idk\": \"I don't know\",\n",
    "\"imao\": \"in my arrogant opinion\",\n",
    "\"imnsho\": \"in my not so humble opinion\",\n",
    "\"imo\": \"in my opinion\",\n",
    "\"iow\": \"in other words\",\n",
    "\"ipn\": \"I’m posting naked\",\n",
    "\"irl\": \"in real life\",\n",
    "\"jk\": \"just kidding\",\n",
    "\"l8r\": \"later\",\n",
    "\"ld\": \"later, dude\",\n",
    "\"ldr\": \"long distance relationship\",\n",
    "\"llta\": \"lots and lots of thunderous applause\",\n",
    "\"lmao\": \"laugh my ass off\",\n",
    "\"lmirl\": \"let's meet in real life\",\n",
    "\"lol\": \"laugh out loud\",\n",
    "\"ltr\": \"longterm relationship\",\n",
    "\"lulab\": \"love you like a brother\",\n",
    "\"lulas\": \"love you like a sister\",\n",
    "\"luv\": \"love\",\n",
    "\"m/f\": \"male or female\",\n",
    "\"m8\": \"mate\",\n",
    "\"milf\": \"mother I would like to fuck\",\n",
    "\"oll\": \"online love\",\n",
    "\"omg\": \"oh my god\",\n",
    "\"otoh\": \"on the other hand\",\n",
    "\"pir\": \"parent in room\",\n",
    "\"ppl\": \"people\",\n",
    "\"r\": \"are\",\n",
    "\"rofl\": \"roll on the floor laughing\",\n",
    "\"rpg\": \"role playing games\",\n",
    "\"ru\": \"are you\",\n",
    "\"shid\": \"slaps head in disgust\",\n",
    "\"somy\": \"sick of me yet\",\n",
    "\"sot\": \"short of time\",\n",
    "\"thanx\": \"thanks\",\n",
    "\"thx\": \"thanks\",\n",
    "\"ttyl\": \"talk to you later\",\n",
    "\"u\": \"you\",\n",
    "\"ur\": \"you are\",\n",
    "\"uw\": \"you’re welcome\",\n",
    "\"wb\": \"welcome back\",\n",
    "\"wfm\": \"works for me\",\n",
    "\"wibni\": \"wouldn't it be nice if\",\n",
    "\"wtf\": \"what the fuck\",\n",
    "\"wtg\": \"way to go\",\n",
    "\"wtgp\": \"want to go private\",\n",
    "\"ym\": \"young man\",\n",
    "\"gr8\": \"great\"\n",
    "}\n",
    "\n",
    "\n",
    "emoticon_dict = {\n",
    "\":)\": \"happy\",\n",
    "\":‑)\": \"happy\",\n",
    "\":-]\": \"happy\",\n",
    "\":-3\": \"happy\",\n",
    "\":->\": \"happy\",\n",
    "\"8-)\": \"happy\",\n",
    "\":-}\": \"happy\",\n",
    "\":o)\": \"happy\",\n",
    "\":c)\": \"happy\",\n",
    "\":^)\": \"happy\",\n",
    "\"=]\": \"happy\",\n",
    "\"=)\": \"happy\",\n",
    "\"<3\": \"happy\",\n",
    "\":-(\": \"sad\",\n",
    "\":(\": \"sad\",\n",
    "\":c\": \"sad\",\n",
    "\":<\": \"sad\",\n",
    "\":[\": \"sad\",\n",
    "\">:[\": \"sad\",\n",
    "\":{\": \"sad\",\n",
    "\">:(\": \"sad\",\n",
    "\":-c\": \"sad\",\n",
    "\":-< \": \"sad\",\n",
    "\":-[\": \"sad\",\n",
    "\":-||\": \"sad\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_tweets.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_tweets.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49159 entries, 0 to 49158\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      49159 non-null  int64  \n",
      " 1   label   31962 non-null  float64\n",
      " 2   tweet   49159 non-null  object \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(combine_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Удалим @user из всех твитов с помощью паттерна \"@[\\w]*\". Для этого создадим функцию: \n",
    " - для того, чтобы найти все вхождения паттерна в тексте, необходимо использовать re.findall(pattern, input_txt)\n",
    " - для для замены @user на пробел, необходимо использовать re.sub()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet'] = combine_df['tweet'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for #lyft credit i can't use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1    0.0    when a father is dysfunctional and is so sel...\n",
       "1   2    0.0    thanks for #lyft credit i can't use cause th...\n",
       "2   3    0.0                                bihday your majesty\n",
       "3   4    0.0  #model   i love u take with u all the time in ...\n",
       "4   5    0.0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все ок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Изменим регистр твитов на нижний с помощью .lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet'] = combine_df['tweet'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16808</th>\n",
       "      <td>16809</td>\n",
       "      <td>1.0</td>\n",
       "      <td>#aleppo #orlando  #syria  #trump  #war #berlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23207</th>\n",
       "      <td>23208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>what a shame to see after 16h of training, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41677</th>\n",
       "      <td>41678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>henry is #allout.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28125</th>\n",
       "      <td>28126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>their lives were taken because they were gay!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33994</th>\n",
       "      <td>33995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#amarinder destroyed #sugarcane industry in #p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45470</th>\n",
       "      <td>45471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beautiful beach #onlyindominicanrepublic #blog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14529</th>\n",
       "      <td>14530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#wild #iris - #nature #photography quality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7208</th>\n",
       "      <td>7209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>achievement unlocked! finally, played on stein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>3400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>in the #gop #deplorable i have seen many \"con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22499</th>\n",
       "      <td>22500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>question is am i more upset about not being ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "16808  16809    1.0  #aleppo #orlando  #syria  #trump  #war #berlin...\n",
       "23207  23208    0.0  what a shame to see after 16h of training, the...\n",
       "41677  41678    NaN                                 henry is #allout. \n",
       "28125  28126    0.0    their lives were taken because they were gay!  \n",
       "33994  33995    NaN  #amarinder destroyed #sugarcane industry in #p...\n",
       "45470  45471    NaN  beautiful beach #onlyindominicanrepublic #blog...\n",
       "14529  14530    0.0      #wild #iris - #nature #photography quality...\n",
       "7208    7209    0.0  achievement unlocked! finally, played on stein...\n",
       "3399    3400    1.0   in the #gop #deplorable i have seen many \"con...\n",
       "22499  22500    0.0  question is am i more upset about not being ab..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Заменим сокращения с апострофами (пример: ain't, can't) на пробел, используя apostrophe_dict. Для этого необходимо сделать функцию: для каждого слова в тексте проверить (for word in text.split()), если слово есть в словаре apostrophe_dict в качестве ключа (сокращенного слова), то заменить ключ на значение (полную версию слова)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_change(row, change_dict):\n",
    "    return ' '.join([change_dict.get(word, word) for word in row['tweet'].split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet'] = combine_df.apply(lambda x: words_change(x, apostrophe_dict), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23024</th>\n",
       "      <td>23025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>so excited for tonight's 'making it happen' aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>3804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>your desire for miscegenation genocide is your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34058</th>\n",
       "      <td>34059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yea he is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33979</th>\n",
       "      <td>33980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ryderrideu - see you c2c and cum together: #sn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46084</th>\n",
       "      <td>46085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>can #lighttherapy help with or #depression? #a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33610</th>\n",
       "      <td>33611</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am so to have this! this makes in #float #pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48745</th>\n",
       "      <td>48746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>check out this new trending #funny #gif ! , 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>8496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i love summer and grillin' #grillingseason #ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47139</th>\n",
       "      <td>47140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am performing this friday 17th june at 9pm, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>7001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>waiting in the dark for my first film of which...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "23024  23025    0.0  so excited for tonight's 'making it happen' aw...\n",
       "3803    3804    0.0  your desire for miscegenation genocide is your...\n",
       "34058  34059    NaN                                          yea he is\n",
       "33979  33980    NaN  ryderrideu - see you c2c and cum together: #sn...\n",
       "46084  46085    NaN  can #lighttherapy help with or #depression? #a...\n",
       "33610  33611    NaN  i am so to have this! this makes in #float #pe...\n",
       "48745  48746    NaN  check out this new trending #funny #gif ! , 30...\n",
       "8495    8496    0.0  i love summer and grillin' #grillingseason #ha...\n",
       "47139  47140    NaN  i am performing this friday 17th june at 9pm, ...\n",
       "7000    7001    0.0  waiting in the dark for my first film of which..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все хорошо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Заменим сокращения на их полные формы, используя short_word_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet'] = combine_df.apply(lambda x: words_change(x, short_word_dict), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27137</th>\n",
       "      <td>27138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>â #gbp/cad resumes decline, hits fresh 1-mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9674</th>\n",
       "      <td>9675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>you will not be punished for your anger, you w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13842</th>\n",
       "      <td>13843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.6.15 #brã¼ssel #13615#onedirection #oneyear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>just bought: 'launch: using design thinking......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48567</th>\n",
       "      <td>48568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it has / it is all about sharing #love and mom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11043</th>\n",
       "      <td>11044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>im passed the point where i need astronomical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39041</th>\n",
       "      <td>39042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>340+ ev for hrc. you shall / you will have a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>20996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>but for realz, where are those jersey pre-orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14607</th>\n",
       "      <td>14608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i need this book asap! wow! #foodporn #vegan #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32697</th>\n",
       "      <td>32698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>brought out the aluminum equipment!!! #collisi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "27137  27138    0.0  â #gbp/cad resumes decline, hits fresh 1-mon...\n",
       "9674    9675    0.0  you will not be punished for your anger, you w...\n",
       "13842  13843    0.0  13.6.15 #brã¼ssel #13615#onedirection #oneyear...\n",
       "759      760    0.0  just bought: 'launch: using design thinking......\n",
       "48567  48568    NaN  it has / it is all about sharing #love and mom...\n",
       "11043  11044    0.0  im passed the point where i need astronomical ...\n",
       "39041  39042    NaN  340+ ev for hrc. you shall / you will have a l...\n",
       "20995  20996    0.0  but for realz, where are those jersey pre-orde...\n",
       "14607  14608    0.0  i need this book asap! wow! #foodporn #vegan #...\n",
       "32697  32698    NaN  brought out the aluminum equipment!!! #collisi..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Заменим эмотиконы (пример: \":)\" = \"happy\") на пробелы, используя emoticon_dict. Для этого воспользуемся функцией, используемой в предыдущем пункте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet'] = combine_df.apply(lambda x: words_change(x, emoticon_dict), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17380</th>\n",
       "      <td>17381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#don't #worry, #be by #kaye #menner #photograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25422</th>\n",
       "      <td>25423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sad when someone cannot love because they were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25354</th>\n",
       "      <td>25355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>used to be one of 4 #movie #theaters in #dabro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27496</th>\n",
       "      <td>27497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>scout meetings are sometimes some of the best ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23428</th>\n",
       "      <td>23429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>there is a mona lisa style to this man's face ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13049</th>\n",
       "      <td>13050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good morning peeps! #buendia #calor #dominican...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32604</th>\n",
       "      <td>32605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>here's a flower for a rainy day ð¸ #london #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42634</th>\n",
       "      <td>42635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>channel in our inner #goddess with this #lunch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23764</th>\n",
       "      <td>23765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>you are welcome already introduced my paner to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23988</th>\n",
       "      <td>23989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the #fbi #corrupt #doj are #hillaryclinton &amp;am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "17380  17381    0.0  #don't #worry, #be by #kaye #menner #photograp...\n",
       "25422  25423    0.0  sad when someone cannot love because they were...\n",
       "25354  25355    0.0  used to be one of 4 #movie #theaters in #dabro...\n",
       "27496  27497    0.0  scout meetings are sometimes some of the best ...\n",
       "23428  23429    0.0  there is a mona lisa style to this man's face ...\n",
       "13049  13050    0.0  good morning peeps! #buendia #calor #dominican...\n",
       "32604  32605    NaN  here's a flower for a rainy day ð¸ #london #...\n",
       "42634  42635    NaN  channel in our inner #goddess with this #lunch...\n",
       "23764  23765    0.0  you are welcome already introduced my paner to...\n",
       "23988  23989    0.0  the #fbi #corrupt #doj are #hillaryclinton &am..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смайликов не осталось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Заменим пунктуацию на пробелы, используя re.sub() и паттерн r'[^\\w\\s]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet'] = combine_df['tweet'].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37550</th>\n",
       "      <td>37551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i work my ass off for my shopping addictions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kanami  amp  sorana ð   â  â  ï  â  ð    thank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37957</th>\n",
       "      <td>37958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more sad news  mr hockey  gordiehowe died  25 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>9978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I am glad lebron finally got what he always wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28225</th>\n",
       "      <td>28226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>workers are good  workers  learn how to  motiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30993</th>\n",
       "      <td>30994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i am thankful for knowledge   thankful  positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14043</th>\n",
       "      <td>14044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i am thankful for my best friends   thankful  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33955</th>\n",
       "      <td>33956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i love summer   â  ï   nofilter  nonmakeup  su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>34297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a amp e cancels controversial unscripted serie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27558</th>\n",
       "      <td>27559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>scheduled delivery is now 23 hrs late  no phon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "37550  37551    NaN       i work my ass off for my shopping addictions\n",
       "1308    1309    0.0  kanami  amp  sorana ð   â  â  ï  â  ð    thank...\n",
       "37957  37958    NaN  more sad news  mr hockey  gordiehowe died  25 ...\n",
       "9977    9978    0.0  I am glad lebron finally got what he always wa...\n",
       "28225  28226    0.0  workers are good  workers  learn how to  motiv...\n",
       "30993  30994    0.0   i am thankful for knowledge   thankful  positive\n",
       "14043  14044    0.0  i am thankful for my best friends   thankful  ...\n",
       "33955  33956    NaN  i love summer   â  ï   nofilter  nonmakeup  su...\n",
       "34296  34297    NaN  a amp e cancels controversial unscripted serie...\n",
       "27558  27559    0.0  scheduled delivery is now 23 hrs late  no phon..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Знаков препинания не осталось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Заменим спец. символы на пробелы, используя re.sub() и паттерн r'[^a-zA-Z0-9]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet'] = combine_df['tweet'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12225</th>\n",
       "      <td>12226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tomhiddleston  s day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17891</th>\n",
       "      <td>17892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nationalbestfriendsday love you jessicalombar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38702</th>\n",
       "      <td>38703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i just got to know about  orlando  but surely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19814</th>\n",
       "      <td>19815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>going to see the stone roses next week</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27236</th>\n",
       "      <td>27237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dreams of home happy  dream  home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31365</th>\n",
       "      <td>31366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>you okay with this of course you are      trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30026</th>\n",
       "      <td>30027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>better get your fix before heading to  brunsco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>1711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i am orlando sad  orlando  rip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47824</th>\n",
       "      <td>47825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>izzybelle at the lake  doubledoodle  doodlesof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18830</th>\n",
       "      <td>18831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>national bestfriend day is just another day wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "12225  12226    0.0                               tomhiddleston  s day\n",
       "17891  17892    0.0   nationalbestfriendsday love you jessicalombar...\n",
       "38702  38703    NaN  i just got to know about  orlando  but surely ...\n",
       "19814  19815    0.0     going to see the stone roses next week        \n",
       "27236  27237    0.0                  dreams of home happy  dream  home\n",
       "31365  31366    1.0  you okay with this of course you are      trai...\n",
       "30026  30027    0.0  better get your fix before heading to  brunsco...\n",
       "1710    1711    0.0                     i am orlando sad  orlando  rip\n",
       "47824  47825    NaN  izzybelle at the lake  doubledoodle  doodlesof...\n",
       "18830  18831    0.0  national bestfriend day is just another day wh..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остались только буквы и цифры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Заменим числа на пробелы, используя re.sub() и паттерн r'[^a-zA-Z]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet'] = combine_df['tweet'].apply(lambda x: re.sub(r'[^a-zA-Z]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35544</th>\n",
       "      <td>35545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ericfriday comparing a political career to  h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29285</th>\n",
       "      <td>29286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fridayyyy              w   minkie  friday  fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31592</th>\n",
       "      <td>31593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>my  guests always have  fun  kayaking  amp  on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15320</th>\n",
       "      <td>15321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>traveling bull up  you will dominate your bul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11628</th>\n",
       "      <td>11629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fathers day  aldubebfathersday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35301</th>\n",
       "      <td>35302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>very impoant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24076</th>\n",
       "      <td>24077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>very to announce our  new  blog  read the firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26388</th>\n",
       "      <td>26389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>you know you are deep  when you try to search ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9447</th>\n",
       "      <td>9448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feels bad when you can   t explains to people ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43130</th>\n",
       "      <td>43131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sad lime is sad  lime  redbubble  stickers  cu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "35544  35545    NaN   ericfriday comparing a political career to  h...\n",
       "29285  29286    0.0  fridayyyy              w   minkie  friday  fri...\n",
       "31592  31593    0.0  my  guests always have  fun  kayaking  amp  on...\n",
       "15320  15321    0.0   traveling bull up  you will dominate your bul...\n",
       "11628  11629    0.0                     fathers day  aldubebfathersday\n",
       "35301  35302    NaN                                      very impoant \n",
       "24076  24077    0.0  very to announce our  new  blog  read the firs...\n",
       "26388  26389    0.0  you know you are deep  when you try to search ...\n",
       "9447    9448    0.0  feels bad when you can   t explains to people ...\n",
       "43130  43131    NaN  sad lime is sad  lime  redbubble  stickers  cu..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остались только буквы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Удалим из текста слова длиной в 1 символ, используя ' '.join([w for w in x.split() if len(w)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet'] = combine_df['tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24423</th>\n",
       "      <td>24424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>model love you take with you all the time in ur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6068</th>\n",
       "      <td>6069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dreamt of you tonight but when finally got to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40405</th>\n",
       "      <td>40406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>thank you so much more bihday day bihday to me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11536</th>\n",
       "      <td>11537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>work work work work work humpday goodmorning w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19942</th>\n",
       "      <td>19943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>got shot at her own conce rip used to always w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26781</th>\n",
       "      <td>26782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pm class and am already here in the classroom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8464</th>\n",
       "      <td>8465</td>\n",
       "      <td>0.0</td>\n",
       "      <td>we are over here making plans to go to raging ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44949</th>\n",
       "      <td>44950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you realize you are responding to fake picture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24897</th>\n",
       "      <td>24898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>check out this shi just cant stop smiling let ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29923</th>\n",
       "      <td>29924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>am celebrated am positive affirmation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "24423  24424    0.0    model love you take with you all the time in ur\n",
       "6068    6069    0.0  dreamt of you tonight but when finally got to ...\n",
       "40405  40406    NaN  thank you so much more bihday day bihday to me...\n",
       "11536  11537    0.0  work work work work work humpday goodmorning w...\n",
       "19942  19943    0.0  got shot at her own conce rip used to always w...\n",
       "26781  26782    0.0  pm class and am already here in the classroom ...\n",
       "8464    8465    0.0  we are over here making plans to go to raging ...\n",
       "44949  44950    NaN  you realize you are responding to fake picture...\n",
       "24897  24898    0.0  check out this shi just cant stop smiling let ...\n",
       "29923  29924    0.0              am celebrated am positive affirmation"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убрали"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Поделим твиты на токены с помощью nltk.tokenize.word_tokenize, создав новый столбец 'tweet_token'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combine_df['tweet_token'] = combine_df['tweet'].apply(lambda x: nltk.tokenize.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28251</th>\n",
       "      <td>28252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>amazing health benefits of cucumbers healthy i...</td>\n",
       "      <td>[amazing, health, benefits, of, cucumbers, hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38928</th>\n",
       "      <td>38929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mindsconsole make mistake that has that is lif...</td>\n",
       "      <td>[mindsconsole, make, mistake, that, has, that,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13063</th>\n",
       "      <td>13064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>national best friend day</td>\n",
       "      <td>[national, best, friend, day]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "28251  28252    0.0  amazing health benefits of cucumbers healthy i...   \n",
       "38928  38929    NaN  mindsconsole make mistake that has that is lif...   \n",
       "13063  13064    0.0                           national best friend day   \n",
       "\n",
       "                                             tweet_token  \n",
       "28251  [amazing, health, benefits, of, cucumbers, hea...  \n",
       "38928  [mindsconsole, make, mistake, that, has, that,...  \n",
       "13063                      [national, best, friend, day]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Удалим стоп-слова из токенов, используя nltk.corpus.stopwords. Создадим столбец 'tweet_token_filtered' без стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_stopwords(tokens, stop_words=stop_words):\n",
    "    return [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet_token_filtered'] = combine_df['tweet_token'].apply(lambda x: del_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0  when father is dysfunctional and is so selfish...   \n",
       "1   2    0.0  thanks for lyft credit cannot use cause they d...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "\n",
       "                                tweet_token_filtered  \n",
       "0  [father, dysfunctional, selfish, drags, kids, ...  \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...  \n",
       "2                                  [bihday, majesty]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалили"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Применим стемминг к токенам с помощью nltk.stem.PorterStemmer. Создадим столбец 'tweet_stemmed' после применения стемминга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_stemming(tokens, stemmer=stemmer):\n",
    "    return [stemmer.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet_stemmed'] = combine_df['tweet_token_filtered'].apply(lambda x: custom_stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48646</th>\n",
       "      <td>48647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>update social analytics beautiful travel motogp</td>\n",
       "      <td>[update, social, analytics, beautiful, travel,...</td>\n",
       "      <td>[update, social, analytics, beautiful, travel,...</td>\n",
       "      <td>[updat, social, analyt, beauti, travel, motogp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>3727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>amateur happy redhead happy redhead redhead pr...</td>\n",
       "      <td>[amateur, happy, redhead, happy, redhead, redh...</td>\n",
       "      <td>[amateur, happy, redhead, happy, redhead, redh...</td>\n",
       "      <td>[amateur, happi, redhead, happi, redhead, redh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>4079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>it cool though at this rate nintendo will be d...</td>\n",
       "      <td>[it, cool, though, at, this, rate, nintendo, w...</td>\n",
       "      <td>[cool, though, rate, nintendo, done, years, ge...</td>\n",
       "      <td>[cool, though, rate, nintendo, done, year, get...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "48646  48647    NaN    update social analytics beautiful travel motogp   \n",
       "3726    3727    0.0  amateur happy redhead happy redhead redhead pr...   \n",
       "4078    4079    0.0  it cool though at this rate nintendo will be d...   \n",
       "\n",
       "                                             tweet_token  \\\n",
       "48646  [update, social, analytics, beautiful, travel,...   \n",
       "3726   [amateur, happy, redhead, happy, redhead, redh...   \n",
       "4078   [it, cool, though, at, this, rate, nintendo, w...   \n",
       "\n",
       "                                    tweet_token_filtered  \\\n",
       "48646  [update, social, analytics, beautiful, travel,...   \n",
       "3726   [amateur, happy, redhead, happy, redhead, redh...   \n",
       "4078   [cool, though, rate, nintendo, done, years, ge...   \n",
       "\n",
       "                                           tweet_stemmed  \n",
       "48646    [updat, social, analyt, beauti, travel, motogp]  \n",
       "3726   [amateur, happi, redhead, happi, redhead, redh...  \n",
       "4078   [cool, though, rate, nintendo, done, year, get...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ок, получилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Применим лемматизацию к токенам с помощью nltk.stem.wordnet.WordNetLemmatizer. Создадим столбец 'tweet_lemmatized' после применения лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_lemmatizer(tokens, lemmatizer=lemmatizer):\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df['tweet_lemmatized'] = combine_df['tweet_token_filtered'].apply(lambda x: custom_lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12054</th>\n",
       "      <td>12055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sun sets and see the wonder of the night posit...</td>\n",
       "      <td>[sun, sets, and, see, the, wonder, of, the, ni...</td>\n",
       "      <td>[sun, sets, see, wonder, night, positivity, ap...</td>\n",
       "      <td>[sun, set, see, wonder, night, posit, appreci,...</td>\n",
       "      <td>[sun, set, see, wonder, night, positivity, app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18021</th>\n",
       "      <td>18022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>we look forward to seeing more adventures</td>\n",
       "      <td>[we, look, forward, to, seeing, more, adventures]</td>\n",
       "      <td>[look, forward, seeing, adventures]</td>\n",
       "      <td>[look, forward, see, adventur]</td>\n",
       "      <td>[look, forward, seeing, adventure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>6075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>never be content to sit back and watch as othe...</td>\n",
       "      <td>[never, be, content, to, sit, back, and, watch...</td>\n",
       "      <td>[never, content, sit, back, watch, others, rig...</td>\n",
       "      <td>[never, content, sit, back, watch, other, righ...</td>\n",
       "      <td>[never, content, sit, back, watch, others, rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12165</th>\n",
       "      <td>12166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>life is what you make of it amp choose make mi...</td>\n",
       "      <td>[life, is, what, you, make, of, it, amp, choos...</td>\n",
       "      <td>[life, make, amp, choose, make, mine, happy, o...</td>\n",
       "      <td>[life, make, amp, choos, make, mine, happi, on...</td>\n",
       "      <td>[life, make, amp, choose, make, mine, happy, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37382</th>\n",
       "      <td>37383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>that ll be right damn freeloading refugee</td>\n",
       "      <td>[that, ll, be, right, damn, freeloading, refugee]</td>\n",
       "      <td>[right, damn, freeloading, refugee]</td>\n",
       "      <td>[right, damn, freeload, refuge]</td>\n",
       "      <td>[right, damn, freeloading, refugee]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44036</th>\n",
       "      <td>44037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>that conference was great</td>\n",
       "      <td>[that, conference, was, great]</td>\n",
       "      <td>[conference, great]</td>\n",
       "      <td>[confer, great]</td>\n",
       "      <td>[conference, great]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22238</th>\n",
       "      <td>22239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>smile with confidence at school backtoschool s...</td>\n",
       "      <td>[smile, with, confidence, at, school, backtosc...</td>\n",
       "      <td>[smile, confidence, school, backtoschool, smil...</td>\n",
       "      <td>[smile, confid, school, backtoschool, smile, s...</td>\n",
       "      <td>[smile, confidence, school, backtoschool, smil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48353</th>\n",
       "      <td>48354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patrons review us on zomato firewoodbiryani</td>\n",
       "      <td>[patrons, review, us, on, zomato, firewoodbiry...</td>\n",
       "      <td>[patrons, review, us, zomato, firewoodbiryani]</td>\n",
       "      <td>[patron, review, us, zomato, firewoodbiryani]</td>\n",
       "      <td>[patron, review, u, zomato, firewoodbiryani]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44100</th>\n",
       "      <td>44101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>allbarzab aint got time prod by np on soundclo...</td>\n",
       "      <td>[allbarzab, aint, got, time, prod, by, np, on,...</td>\n",
       "      <td>[allbarzab, aint, got, time, prod, np, soundcl...</td>\n",
       "      <td>[allbarzab, aint, got, time, prod, np, soundcl...</td>\n",
       "      <td>[allbarzab, aint, got, time, prod, np, soundcl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19246</th>\n",
       "      <td>19247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>saw miller lite beer</td>\n",
       "      <td>[saw, miller, lite, beer]</td>\n",
       "      <td>[saw, miller, lite, beer]</td>\n",
       "      <td>[saw, miller, lite, beer]</td>\n",
       "      <td>[saw, miller, lite, beer]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "12054  12055    0.0  sun sets and see the wonder of the night posit...   \n",
       "18021  18022    0.0          we look forward to seeing more adventures   \n",
       "6074    6075    1.0  never be content to sit back and watch as othe...   \n",
       "12165  12166    0.0  life is what you make of it amp choose make mi...   \n",
       "37382  37383    NaN          that ll be right damn freeloading refugee   \n",
       "44036  44037    NaN                          that conference was great   \n",
       "22238  22239    0.0  smile with confidence at school backtoschool s...   \n",
       "48353  48354    NaN        patrons review us on zomato firewoodbiryani   \n",
       "44100  44101    NaN  allbarzab aint got time prod by np on soundclo...   \n",
       "19246  19247    0.0                               saw miller lite beer   \n",
       "\n",
       "                                             tweet_token  \\\n",
       "12054  [sun, sets, and, see, the, wonder, of, the, ni...   \n",
       "18021  [we, look, forward, to, seeing, more, adventures]   \n",
       "6074   [never, be, content, to, sit, back, and, watch...   \n",
       "12165  [life, is, what, you, make, of, it, amp, choos...   \n",
       "37382  [that, ll, be, right, damn, freeloading, refugee]   \n",
       "44036                     [that, conference, was, great]   \n",
       "22238  [smile, with, confidence, at, school, backtosc...   \n",
       "48353  [patrons, review, us, on, zomato, firewoodbiry...   \n",
       "44100  [allbarzab, aint, got, time, prod, by, np, on,...   \n",
       "19246                          [saw, miller, lite, beer]   \n",
       "\n",
       "                                    tweet_token_filtered  \\\n",
       "12054  [sun, sets, see, wonder, night, positivity, ap...   \n",
       "18021                [look, forward, seeing, adventures]   \n",
       "6074   [never, content, sit, back, watch, others, rig...   \n",
       "12165  [life, make, amp, choose, make, mine, happy, o...   \n",
       "37382                [right, damn, freeloading, refugee]   \n",
       "44036                                [conference, great]   \n",
       "22238  [smile, confidence, school, backtoschool, smil...   \n",
       "48353     [patrons, review, us, zomato, firewoodbiryani]   \n",
       "44100  [allbarzab, aint, got, time, prod, np, soundcl...   \n",
       "19246                          [saw, miller, lite, beer]   \n",
       "\n",
       "                                           tweet_stemmed  \\\n",
       "12054  [sun, set, see, wonder, night, posit, appreci,...   \n",
       "18021                     [look, forward, see, adventur]   \n",
       "6074   [never, content, sit, back, watch, other, righ...   \n",
       "12165  [life, make, amp, choos, make, mine, happi, on...   \n",
       "37382                    [right, damn, freeload, refuge]   \n",
       "44036                                    [confer, great]   \n",
       "22238  [smile, confid, school, backtoschool, smile, s...   \n",
       "48353      [patron, review, us, zomato, firewoodbiryani]   \n",
       "44100  [allbarzab, aint, got, time, prod, np, soundcl...   \n",
       "19246                          [saw, miller, lite, beer]   \n",
       "\n",
       "                                        tweet_lemmatized  \n",
       "12054  [sun, set, see, wonder, night, positivity, app...  \n",
       "18021                 [look, forward, seeing, adventure]  \n",
       "6074   [never, content, sit, back, watch, others, rig...  \n",
       "12165  [life, make, amp, choose, make, mine, happy, o...  \n",
       "37382                [right, damn, freeloading, refugee]  \n",
       "44036                                [conference, great]  \n",
       "22238  [smile, confidence, school, backtoschool, smil...  \n",
       "48353       [patron, review, u, zomato, firewoodbiryani]  \n",
       "44100  [allbarzab, aint, got, time, prod, np, soundcl...  \n",
       "19246                          [saw, miller, lite, beer]  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Сохраним результат предобработки в pickle-файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_df.to_pickle('prepared_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
